{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from models import *\n",
    "from configs import cfg\n",
    "import pandas as pd\n",
    "from nltk.translate import bleu_score\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(fname):\n",
    "    # From the csv file given by filename and return a pandas DataFrame of the read csv.\n",
    "    \n",
    "    # Define path to data\n",
    "    # Note: Path relative to KHIEM's files, make changes to relative path if necessary\n",
    "    dataPath = 'BeerAdvocatePA4/' + fname\n",
    "    \n",
    "    # Read csv into pandas frame\n",
    "    df = pd.read_csv(dataPath)\n",
    "    \n",
    "    # Return frame\n",
    "    return df\n",
    "\n",
    "def char2oh(padded,translate, beers):\n",
    "    # Each row has form: beer style index||overall||character indices\n",
    "    # TODO: Onehot the beer style and concatenate to overall\n",
    "    # Onehot the character indices and concatenate the beerstyle||overall to each onehotted char\n",
    "    \n",
    "    # Each row's beer has form 1x#ofpossiblebeers\n",
    "    beerstyles = np.zeros((padded.shape[0],len(beers)))\n",
    "    # Each row's review has form max(lenofsequence) x #ofpossiblecharacters\n",
    "    # Since we padded each review, they all have the same number of characters\n",
    "    # Subtract two since we know the first two values aren't characters\n",
    "    chars = np.zeros((padded.shape[0], (padded.shape[1] - 2), len(translate)))\n",
    "    \n",
    "    # First two columns are beerstyle indices and overalls\n",
    "    bsidx = padded[:,0]\n",
    "    ovrl = padded[:,1]\n",
    "    \n",
    "    # The rest are characters\n",
    "    ch = padded[:,2:]\n",
    "    \n",
    "    # Index with bsidx\n",
    "    beerstyles[np.arange(padded.shape[0]), bsidx.astype(int)] = 1\n",
    "    \n",
    "    igrid = np.mgrid[0:padded.shape[0], 0:(padded.shape[1]-2)]\n",
    "    # Index with ch, we use meshgrid since this is a 3d array\n",
    "    chars[igrid[0], igrid[1], ch.astype(int)] = 1\n",
    "    \n",
    "    # Concatenate overall and beer style\n",
    "    meta_data = np.c_[ovrl, beerstyles]\n",
    "    \n",
    "    # Tile and reshape meta_data so we have a copy for each one of the characters\n",
    "    tiled_meta = np.tile(meta_data, padded.shape[1] - 2).reshape(padded.shape[0], (padded.shape[1] - 2), -1)\n",
    "    \n",
    "    # Concatenate the items \n",
    "    return np.c_[tiled_meta, chars]\n",
    "    \n",
    "\n",
    "def process_train_data(data):\n",
    "    # TODO: Input is a pandas DataFrame and return a numpy array (or a torch Tensor/ Variable)\n",
    "    # that has all features (including characters in one hot encoded form).\n",
    "\n",
    "    # Get the dictionary to translate between ASCII and onehot index\n",
    "    with open(\"ASCII2oneHot.pkl\", \"rb\") as f:\n",
    "        translate = pickle.load(f)\n",
    "    \n",
    "    # Get the dictionary to translate between beer style and index\n",
    "    with open(\"BeerDict.pkl\", \"rb\") as f:\n",
    "        beers = pickle.load(f)\n",
    "        \n",
    "    # List of reviews to onehot after translation\n",
    "    toOnehot = []\n",
    "    \n",
    "    # For each review, convert to list of its translated characters\n",
    "    # Translated means ord(c) -> onehot index\n",
    "    # Also translate the beer style to its index value\n",
    "    # Concatenate all the data and convert to tensor\n",
    "    for idx,rev in data.iterrows():\n",
    "        toOnehot.append(torch.Tensor([beers[rev['beer/style']]] + [rev['review/overall']] + \n",
    "                                     [translate[ord(x)] for x in list(chr(0)+rev['review/text']+chr(1))]))\n",
    "    \n",
    "    # Pad all smaller sentences with 1s to signify <EOS>\n",
    "    padded = torch.nn.utils.rnn.pad_sequence(sorted(toOnehot, key = lambda x: len(x), reverse=True), \n",
    "                                           batch_first=True, padding_value=translate[1])\n",
    "\n",
    "    # Take the array padded sentences and one-hot the characters.\n",
    "    # Beer style also gets one-hot\n",
    "    # Overall does not\n",
    "    \n",
    "    # Parse out labels\n",
    "    padded = char2oh(np.array(padded), translate, beers)\n",
    "    \n",
    "    return padded\n",
    "    \n",
    "    \n",
    "def train_valid_split(data):\n",
    "    # TODO: Takes in train data as dataframe and\n",
    "    # splits it into training and validation data.\n",
    "    \n",
    "    # List of indices of the data\n",
    "    ind = np.arange(len(data))\n",
    "    \n",
    "    # Randomize the split\n",
    "    np.random.shuffle(ind)\n",
    "    \n",
    "    # Where to split the indices\n",
    "    # We'll take first 20% for validation, the rest for training\n",
    "    split = int(0.2*len(data))\n",
    "    \n",
    "    # Split the indices\n",
    "    vIndices = ind[0:split]\n",
    "    tIndices = ind[split:]\n",
    "    \n",
    "    # Group the indices into their frames then return those\n",
    "    validation_data = data.iloc[vIndices]\n",
    "    train_data = data.iloc[tIndices]\n",
    "    \n",
    "    return train_data,validation_data\n",
    "    \n",
    "def process_test_data(data):\n",
    "    # TODO: Takes in pandas DataFrame and returns a numpy array (or a torch Tensor/ Variable)\n",
    "    # that has all input features. Note that test data does not contain any review so you don't\n",
    "    # have to worry about one hot encoding the data.\n",
    "    raise NotImplementedError\n",
    "\n",
    "    \n",
    "def pad_data(orig_data):\n",
    "    # TODO: Since you will be training in batches and training sample of each batch may have reviews\n",
    "    # of varying lengths, you will need to pad your data so that all samples have reviews of length\n",
    "    # equal to the longest review in a batch. You will pad all the sequences with <EOS> character \n",
    "    # representation in one hot encoding.\n",
    "    raise NotImplementedError\n",
    "    \n",
    "\n",
    "def getBatchIter(data, batchSize):\n",
    "    # TODO: Returns a list of batches of indices\n",
    "    # The list of batch indices will be used to index into the\n",
    "    # corresponding data frame to extract the data\n",
    "    \n",
    "    # List of all possible indices\n",
    "    ind = np.arange(len(data))\n",
    "    \n",
    "    # Calculate how many batches of batchSize would fit into\n",
    "    # into the length of the data\n",
    "    numBatches = int(len(data)/batchSize)\n",
    "    \n",
    "    # Split the array of indices into roughly equivalent batch sized batches\n",
    "    batchedInd = np.array_split(ind, numBatches)\n",
    "    \n",
    "    return batchedInd\n",
    "    \n",
    "    \n",
    "def train(model, X_train, X_valid, cfg):\n",
    "    # TODO: Train the model!\n",
    "    # Datas are given as pandas data frame. Call process on-line as we train to\n",
    "    # get the data and label\n",
    "    \n",
    "    # Size of each batch\n",
    "    batchSize = 64\n",
    "    \n",
    "    # Create the batch iterator for the data\n",
    "    trainIter = getBatchIter(X_train, batchSize)\n",
    "    validIter = getBatchIter(X_valid, batchSize)\n",
    "    \n",
    "    # Training loop\n",
    "    for batch_count, batchInd in enumerate(trainIter,0):\n",
    "        # Get the dataframe for the batch\n",
    "        batchFrame = X_train.iloc[batchInd]\n",
    "        \n",
    "        # Process the batch for data and labels\n",
    "        corpus, labels = process_train_data(batchFrame)\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "def generate(model, X_test, cfg):\n",
    "    # TODO: Given n rows in test data, generate a list of n strings, where each string is the review\n",
    "    # corresponding to each input row in test data.\n",
    "    raise NotImplementedError\n",
    "    \n",
    "    \n",
    "def save_to_file(outputs, fname):\n",
    "    # TODO: Given the list of generated review outputs and output file name, save all these reviews to\n",
    "    # the file in .txt format.\n",
    "    raise NotImplementedError\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-848bd0c9db30>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomputing_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Train the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Generate the outputs for test data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0msave_to_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_fname\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Save the generated outputs to a file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-8ef2c5750f97>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, X_train, X_valid, cfg)\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m         \u001b[1;31m# Process the batch for data and labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 152\u001b[1;33m         \u001b[0mcorpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprocess_train_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatchFrame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    train_data_fname = \"Beeradvocate_Train.csv\"\n",
    "    test_data_fname = \"Beeradvocate_Test.csv\"\n",
    "    out_fname = \"model_outputs.out\"\n",
    "    \n",
    "    train_data = load_data(train_data_fname) # Generating the pandas DataFrame\n",
    "    test_data = load_data(test_data_fname) # Generating the pandas DataFrame\n",
    "    X_train, X_valid = train_valid_split(train_data) # Splitting the train data into train-valid data\n",
    "    \n",
    "    model = baselineLSTM(cfg) # Replace this with model = <your model name>(cfg)\n",
    "    if cfg['cuda']:\n",
    "        computing_device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        computing_device = torch.device(\"cpu\")\n",
    "    model.to(computing_device)\n",
    "    \n",
    "    train(model, X_train, X_valid, cfg) # Train the model\n",
    "    outputs = generate(model, X_test, cfg) # Generate the outputs for test data\n",
    "    save_to_file(outputs, out_fname) # Save the generated outputs to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>beer/name</th>\n",
       "      <th>beer/beerId</th>\n",
       "      <th>beer/brewerId</th>\n",
       "      <th>beer/ABV</th>\n",
       "      <th>beer/style</th>\n",
       "      <th>review/appearance</th>\n",
       "      <th>review/aroma</th>\n",
       "      <th>review/palate</th>\n",
       "      <th>review/taste</th>\n",
       "      <th>review/overall</th>\n",
       "      <th>review/time</th>\n",
       "      <th>review/profileName</th>\n",
       "      <th>review/text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>855192</th>\n",
       "      <td>855192</td>\n",
       "      <td>All Others Pale</td>\n",
       "      <td>41009</td>\n",
       "      <td>13307</td>\n",
       "      <td>6.0</td>\n",
       "      <td>American Pale Ale (APA)</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1238360333</td>\n",
       "      <td>mikesgroove</td>\n",
       "      <td>My first beer in nearly two weeks as I have be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865928</th>\n",
       "      <td>865928</td>\n",
       "      <td>Mamma Mia! Pizza Beer</td>\n",
       "      <td>41127</td>\n",
       "      <td>16836</td>\n",
       "      <td>4.6</td>\n",
       "      <td>Herbed / Spiced Beer</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1224865806</td>\n",
       "      <td>nightcrawler</td>\n",
       "      <td>Bought this to give it a try. What the heck.\\t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872855</th>\n",
       "      <td>872855</td>\n",
       "      <td>Stone 07.07.07 Vertical Epic Ale</td>\n",
       "      <td>37326</td>\n",
       "      <td>147</td>\n",
       "      <td>8.4</td>\n",
       "      <td>Belgian Strong Pale Ale</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1184961073</td>\n",
       "      <td>dblinkhorn</td>\n",
       "      <td>Poured from a 22oz bomber into a tulip glass.\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62170</th>\n",
       "      <td>62170</td>\n",
       "      <td>100% Barrel Fermented Autumn Maple</td>\n",
       "      <td>61151</td>\n",
       "      <td>16866</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Fruit / Vegetable Beer</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1305407811</td>\n",
       "      <td>black13</td>\n",
       "      <td>Thanks to Vitese for sending me this bottle. I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159341</th>\n",
       "      <td>159341</td>\n",
       "      <td>IPA (India Pale Ale)</td>\n",
       "      <td>9088</td>\n",
       "      <td>3818</td>\n",
       "      <td>7.3</td>\n",
       "      <td>American IPA</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1275452010</td>\n",
       "      <td>jzeilinger</td>\n",
       "      <td>A - Pours a clear orange color, creamy white h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671221</th>\n",
       "      <td>671221</td>\n",
       "      <td>Cascazilla</td>\n",
       "      <td>18721</td>\n",
       "      <td>651</td>\n",
       "      <td>7.0</td>\n",
       "      <td>American Amber / Red Ale</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1292727882</td>\n",
       "      <td>coalcracker</td>\n",
       "      <td>Appearance: Pours a truly amber color with sub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422916</th>\n",
       "      <td>422916</td>\n",
       "      <td>Great Lakes Edmund Fitzgerald Porter</td>\n",
       "      <td>226</td>\n",
       "      <td>73</td>\n",
       "      <td>5.8</td>\n",
       "      <td>American Porter</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1252161432</td>\n",
       "      <td>mhatters</td>\n",
       "      <td>Served on-tap at TJs in Paoli\\t\\tPours a deep ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1136812</th>\n",
       "      <td>1136812</td>\n",
       "      <td>Pliny The Younger</td>\n",
       "      <td>21690</td>\n",
       "      <td>863</td>\n",
       "      <td>11.0</td>\n",
       "      <td>American Double / Imperial IPA</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1132707447</td>\n",
       "      <td>kmpitz2</td>\n",
       "      <td>Pours a hazy peach color with a 2 finger white...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139348</th>\n",
       "      <td>1139348</td>\n",
       "      <td>Aud Blonde</td>\n",
       "      <td>27057</td>\n",
       "      <td>863</td>\n",
       "      <td>4.5</td>\n",
       "      <td>American Blonde Ale</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1298097672</td>\n",
       "      <td>BerkeleyBeerMan</td>\n",
       "      <td>Drank this on tap at the Russian river brewing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>848207</th>\n",
       "      <td>848207</td>\n",
       "      <td>Naughty Hildegard ESB</td>\n",
       "      <td>56157</td>\n",
       "      <td>18858</td>\n",
       "      <td>6.5</td>\n",
       "      <td>Extra Special / Strong Bitter (ESB)</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1309057236</td>\n",
       "      <td>northyorksammy</td>\n",
       "      <td>Fresh bottle from rutager. Pours tan brown bod...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0                             beer/name  beer/beerId  \\\n",
       "855192       855192                       All Others Pale        41009   \n",
       "865928       865928                 Mamma Mia! Pizza Beer        41127   \n",
       "872855       872855      Stone 07.07.07 Vertical Epic Ale        37326   \n",
       "62170         62170    100% Barrel Fermented Autumn Maple        61151   \n",
       "159341       159341                  IPA (India Pale Ale)         9088   \n",
       "671221       671221                            Cascazilla        18721   \n",
       "422916       422916  Great Lakes Edmund Fitzgerald Porter          226   \n",
       "1136812     1136812                     Pliny The Younger        21690   \n",
       "1139348     1139348                            Aud Blonde        27057   \n",
       "848207       848207                 Naughty Hildegard ESB        56157   \n",
       "\n",
       "         beer/brewerId  beer/ABV                           beer/style  \\\n",
       "855192           13307       6.0              American Pale Ale (APA)   \n",
       "865928           16836       4.6                 Herbed / Spiced Beer   \n",
       "872855             147       8.4              Belgian Strong Pale Ale   \n",
       "62170            16866      10.0               Fruit / Vegetable Beer   \n",
       "159341            3818       7.3                         American IPA   \n",
       "671221             651       7.0             American Amber / Red Ale   \n",
       "422916              73       5.8                      American Porter   \n",
       "1136812            863      11.0       American Double / Imperial IPA   \n",
       "1139348            863       4.5                  American Blonde Ale   \n",
       "848207           18858       6.5  Extra Special / Strong Bitter (ESB)   \n",
       "\n",
       "         review/appearance  review/aroma  review/palate  review/taste  \\\n",
       "855192                 4.5           4.0            4.0           4.0   \n",
       "865928                 3.0           1.5            2.5           1.5   \n",
       "872855                 4.0           4.0            3.5           4.0   \n",
       "62170                  4.0           4.0            4.0           4.0   \n",
       "159341                 3.5           4.0            4.0           3.5   \n",
       "671221                 4.0           3.5            4.0           4.0   \n",
       "422916                 4.0           4.5            4.0           4.5   \n",
       "1136812                4.0           4.5            5.0           5.0   \n",
       "1139348                3.5           4.0            4.0           3.5   \n",
       "848207                 3.5           3.5            3.5           2.5   \n",
       "\n",
       "         review/overall  review/time review/profileName  \\\n",
       "855192              4.0   1238360333        mikesgroove   \n",
       "865928              1.5   1224865806       nightcrawler   \n",
       "872855              4.0   1184961073         dblinkhorn   \n",
       "62170               4.0   1305407811            black13   \n",
       "159341              4.5   1275452010         jzeilinger   \n",
       "671221              4.0   1292727882        coalcracker   \n",
       "422916              4.0   1252161432           mhatters   \n",
       "1136812             5.0   1132707447            kmpitz2   \n",
       "1139348             4.0   1298097672    BerkeleyBeerMan   \n",
       "848207              2.0   1309057236     northyorksammy   \n",
       "\n",
       "                                               review/text  \n",
       "855192   My first beer in nearly two weeks as I have be...  \n",
       "865928   Bought this to give it a try. What the heck.\\t...  \n",
       "872855   Poured from a 22oz bomber into a tulip glass.\\...  \n",
       "62170    Thanks to Vitese for sending me this bottle. I...  \n",
       "159341   A - Pours a clear orange color, creamy white h...  \n",
       "671221   Appearance: Pours a truly amber color with sub...  \n",
       "422916   Served on-tap at TJs in Paoli\\t\\tPours a deep ...  \n",
       "1136812  Pours a hazy peach color with a 2 finger white...  \n",
       "1139348  Drank this on tap at the Russian river brewing...  \n",
       "848207   Fresh bottle from rutager. Pours tan brown bod...  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "   train_data, train_labels = process_train_data(train_data) # Converting DataFrame to numpy array\n",
    "    X_test = process_test_data(test_data) # Converting DataFrame to numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = pd.read_csv('BeerAdvocatePA4/Beeradvocate_Train.csv', chunksize = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for idx,chnk in enumerate(n,0):\n",
    "    print(idx)\n",
    "    res = process_train_data(chnk)\n",
    "    with open('Processed/chnk'+str(idx)+'.prc', 'wb+') as f:\n",
    "        pickle.dump(res,f, pickle.HIGHEST_PROTOCOL)\n",
    "    del res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
