{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from models import *\n",
    "from configs import cfg\n",
    "import pandas as pd\n",
    "from nltk.translate import bleu_score\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(fname):\n",
    "    # From the csv file given by filename and return a pandas DataFrame of the read csv.\n",
    "    \n",
    "    # Define path to data\n",
    "    # Note: Path relative to KHIEM's files, make changes to relative path if necessary\n",
    "    dataPath = 'BeerAdvocatePA4/' + fname\n",
    "    \n",
    "    # Read csv into pandas frame\n",
    "    df = pd.read_csv(dataPath)\n",
    "    \n",
    "    # Return frame\n",
    "    return df\n",
    "\n",
    "def char2oh(padded,translate, beers):\n",
    "    # Each row has form: beer style index||overall||character indices\n",
    "    # TODO: Onehot the beer style and concatenate to overall\n",
    "    # Onehot the character indices and concatenate the beerstyle||overall to each onehotted char\n",
    "    \n",
    "    # Each row's beer has form 1x#ofpossiblebeers\n",
    "    beerstyles = np.zeros((padded.shape[0],len(beers)))\n",
    "    # Each row's review has form max(lenofsequence) x #ofpossiblecharacters\n",
    "    # Since we padded each review, they all have the same number of characters\n",
    "    # Subtract two since we know the first two values aren't characters\n",
    "    chars = np.zeros((padded.shape[0], (padded.shape[1] - 2), len(translate)))\n",
    "    \n",
    "    # First two columns are beerstyle indices and overalls\n",
    "    bsidx = padded[:,0]\n",
    "    ovrl = padded[:,1]\n",
    "    \n",
    "    # The rest are characters\n",
    "    ch = padded[:,2:]\n",
    "    \n",
    "    # Index with bsidx\n",
    "    beerstyles[np.arange(padded.shape[0]), bsidx.astype(int)] = 1\n",
    "    \n",
    "    igrid = np.mgrid[0:padded.shape[0], 0:(padded.shape[1]-2)]\n",
    "    # Index with ch, we use meshgrid since this is a 3d array\n",
    "    chars[igrid[0], igrid[1], ch.astype(int)] = 1\n",
    "    \n",
    "    # Concatenate overall and beer style\n",
    "    meta_data = np.c_[ovrl, beerstyles]\n",
    "    \n",
    "    # Tile and reshape meta_data so we have a copy for each one of the characters\n",
    "    tiled_meta = np.tile(meta_data, padded.shape[1] - 2).reshape(padded.shape[0], (padded.shape[1] - 2), -1)\n",
    "    \n",
    "    # Concatenate the items \n",
    "    \n",
    "    # Return both the concatenated and just the one hot\n",
    "    return np.c_[tiled_meta, chars],chars\n",
    "    \n",
    "\n",
    "def process_train_data(data):\n",
    "    # TODO: Input is a pandas DataFrame and return a numpy array (or a torch Tensor/ Variable)\n",
    "    # that has all features (including characters in one hot encoded form).\n",
    "\n",
    "    # Get the dictionary to translate between ASCII and onehot index\n",
    "    with open(\"ASCII2oneHot.pkl\", \"rb\") as f:\n",
    "        translate = pickle.load(f)\n",
    "    \n",
    "    # Get the dictionary to translate between beer style and index\n",
    "    with open(\"BeerDict.pkl\", \"rb\") as f:\n",
    "        beers = pickle.load(f)\n",
    "        \n",
    "    # List of reviews to onehot after translation\n",
    "    toOnehot = []\n",
    "    \n",
    "    # For each review, convert to list of its translated characters\n",
    "    # Translated means ord(c) -> onehot index\n",
    "    # Also translate the beer style to its index value\n",
    "    # Concatenate all the data and convert to tensor\n",
    "    for idx,rev in data.iterrows():\n",
    "        if isinstance(rev['review/text'], str):\n",
    "            toOnehot.append(torch.Tensor([beers[rev['beer/style']]] + [rev['review/overall']] + \n",
    "                                         [translate[ord(x)] for x in list(chr(0)+rev['review/text']+chr(1))]))\n",
    "    \n",
    "    # Pad all smaller sentences with 1s to signify <EOS>\n",
    "    padded = pad_data(toOnehot, translate[1])\n",
    "    del toOnehot\n",
    "\n",
    "    # Take the array padded sentences and one-hot the characters.\n",
    "    # Beer style also gets one-hot\n",
    "    # Overall does not\n",
    "    reviews,labels = char2oh(np.array(padded), translate, beers)\n",
    "    del padded\n",
    "    \n",
    "    # Since the labels are simply the next characters, we take all characters except the last one\n",
    "    # for the review, and everything but the first one for the labels\n",
    "    # Argmax to get back the character indices for the labels\n",
    "    return torch.Tensor(reviews[:,0:-1,:]), torch.Tensor(labels[:,1:,:]).argmax(dim=2)\n",
    "    \n",
    "    \n",
    "def train_valid_split(data):\n",
    "    # TODO: Takes in train data as dataframe and\n",
    "    # splits it into training and validation data.\n",
    "    \n",
    "    # List of indices of the data\n",
    "    ind = np.arange(len(data))\n",
    "    \n",
    "    # Randomize the split\n",
    "    np.random.shuffle(ind)\n",
    "    \n",
    "    # Where to split the indices\n",
    "    # We'll take first 20% for validation, the rest for training\n",
    "    split = int(0.2*len(data))\n",
    "    \n",
    "    # Split the indices\n",
    "    vIndices = ind[0:split]\n",
    "    tIndices = ind[split:]\n",
    "    \n",
    "    # Group the indices into their frames then return those\n",
    "    validation_data = data.iloc[vIndices]\n",
    "    train_data = data.iloc[tIndices]\n",
    "    \n",
    "    return train_data,validation_data\n",
    "    \n",
    "def process_test_data(data):\n",
    "    # TODO: Takes in pandas DataFrame and returns a numpy array (or a torch Tensor/ Variable)\n",
    "    # that has all input features. Note that test data does not contain any review so you don't\n",
    "    # have to worry about one hot encoding the data.\n",
    "    raise NotImplementedError\n",
    "\n",
    "    \n",
    "def pad_data(orig_data, pad):\n",
    "    # TODO: Since you will be training in batches and training sample of each batch may have reviews\n",
    "    # of varying lengths, you will need to pad your data so that all samples have reviews of length\n",
    "    # equal to the longest review in a batch. You will pad all the sequences with <EOS> character \n",
    "    # representation in one hot encoding.\n",
    "    # Data comes in as translated ASCII representation, simply sort and call torch pad\n",
    "    return torch.nn.utils.rnn.pad_sequence(sorted(orig_data, key = lambda x: len(x), reverse=True), \n",
    "                                           batch_first=True, padding_value=pad)\n",
    "    \n",
    "\n",
    "def getBatchIter(data, batchSize):\n",
    "    # TODO: Returns a list of batches of indices\n",
    "    # The list of batch indices will be used to index into the\n",
    "    # corresponding data frame to extract the data\n",
    "    \n",
    "    # List of all possible indices\n",
    "    ind = np.arange(len(data))\n",
    "    \n",
    "    # Calculate how many batches of batchSize would fit into\n",
    "    # into the length of the data\n",
    "    numBatches = int(len(data)/batchSize)\n",
    "    \n",
    "    # Split the array of indices into roughly equivalent batch sized batches\n",
    "    batchedInd = np.array_split(ind, numBatches)\n",
    "    \n",
    "    return batchedInd\n",
    "    \n",
    "    \n",
    "def train(model, X_train, X_valid, cfg):\n",
    "    # TODO: Train the model!\n",
    "    # Datas are given as pandas data frame. Call process on-line as we train to\n",
    "    # get the data and label\n",
    "    \n",
    "    epochs = np.arange(1)\n",
    "    l_rate = cfg['learning_rate']\n",
    "    penalty = cfg['L2_penalty']\n",
    "    \n",
    "    \n",
    "    # Define loss and optimizer\n",
    "    Criterion = torch.nn.NLLLoss() # We'll use NLL\n",
    "    Optimizer = optim.Adam(model.parameters(), lr=l_rate, weight_decay=penalty) # Let's use ADAM\n",
    "    \n",
    "    # Size of each batch\n",
    "    batchSize = 150\n",
    "    \n",
    "    # Create the batch iterator for the data\n",
    "    trainIter = getBatchIter(X_train, batchSize)\n",
    "    validIter = getBatchIter(X_valid, batchSize)\n",
    "    \n",
    "    all_loss = []\n",
    "    for e in epochs:\n",
    "        batch_loss = 0\n",
    "        # Training loop\n",
    "        for batch_count, batchInd in enumerate(trainIter,0):\n",
    "            # Get the dataframe for the batch\n",
    "            batchFrame = X_train.iloc[batchInd]\n",
    "\n",
    "            # Process the batch for data and labels\n",
    "            batch, labels = process_train_data(batchFrame)\n",
    "            batch,labels = batch.to(computing_device), labels.to(computing_device)\n",
    "\n",
    "            # TODO: Actual fuckin train lmao\n",
    "\n",
    "            # Run our batch through the model\n",
    "            # batch has shape Batchsize x Seqlen x Input Dim\n",
    "            output, (h,c) = model(batch)\n",
    "            \n",
    "            # Save space\n",
    "            del h\n",
    "            del c\n",
    "            \n",
    "            # Reshape the output and labels to so that the loss function\n",
    "            # can simply interpret time as another batch\n",
    "            # This will be fine since sum of sum can be thought of as just\n",
    "            # one sum\n",
    "            output = output.view(output.shape[0]*output.shape[1], output.shape[2])\n",
    "            labels = labels.view(-1)\n",
    "\n",
    "            # Get loss and compute gradients\n",
    "            loss = Criterion(output,labels)\n",
    "            loss.backward()\n",
    "            del output\n",
    "\n",
    "            batch_loss += float(loss)\n",
    "            del loss\n",
    "            \n",
    "            # Optimize step\n",
    "            Optimizer.step()\n",
    "\n",
    "            # Progress bar\n",
    "            if batch_count % 50 == 0 and batch_count > 0:\n",
    "                batch_loss /= 50\n",
    "                print(\"On batch %d with loss %f\" % (batch_count, batch_loss))\n",
    "                all_loss.append(batch_loss)\n",
    "                \n",
    "            \n",
    "        print(\"Completed epoch %d\" % e)\n",
    "    \n",
    "    print(\"Completed Training\")\n",
    "        \n",
    "    \n",
    "    \n",
    "def generate(model, X_test, cfg):\n",
    "    # TODO: Given n rows in test data, generate a list of n strings, where each string is the review\n",
    "    # corresponding to each input row in test data.\n",
    "    raise NotImplementedError\n",
    "    \n",
    "    \n",
    "def save_to_file(outputs, fname):\n",
    "    # TODO: Given the list of generated review outputs and output file name, save all these reviews to\n",
    "    # the file in .txt format.\n",
    "    raise NotImplementedError\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On batch 1 with loss 0.188830\n",
      "On batch 2 with loss 0.096572\n",
      "On batch 3 with loss 0.092879\n",
      "On batch 4 with loss 0.091354\n",
      "On batch 5 with loss 0.091814\n",
      "On batch 6 with loss 0.090613\n",
      "On batch 7 with loss 0.092001\n",
      "On batch 8 with loss 0.091314\n",
      "On batch 9 with loss 0.090576\n",
      "On batch 10 with loss 0.091126\n",
      "On batch 11 with loss 0.090969\n",
      "On batch 12 with loss 0.091668\n",
      "On batch 13 with loss 0.092555\n",
      "On batch 14 with loss 0.090852\n",
      "On batch 15 with loss 0.091234\n",
      "On batch 16 with loss 0.091067\n",
      "On batch 17 with loss 0.091175\n",
      "On batch 18 with loss 0.091651\n",
      "On batch 19 with loss 0.091109\n",
      "On batch 20 with loss 0.090930\n",
      "On batch 21 with loss 0.091982\n",
      "On batch 22 with loss 0.090757\n",
      "On batch 23 with loss 0.090829\n",
      "On batch 24 with loss 0.091735\n",
      "On batch 25 with loss 0.090333\n",
      "On batch 26 with loss 0.090888\n",
      "On batch 27 with loss 0.090429\n",
      "On batch 28 with loss 0.091963\n",
      "On batch 29 with loss 0.090941\n",
      "On batch 30 with loss 0.090744\n",
      "On batch 31 with loss 0.091633\n",
      "On batch 32 with loss 0.090942\n",
      "On batch 33 with loss 0.091590\n",
      "On batch 34 with loss 0.090640\n",
      "On batch 35 with loss 0.090986\n",
      "On batch 36 with loss 0.091319\n",
      "On batch 37 with loss 0.091080\n",
      "On batch 38 with loss 0.091823\n",
      "On batch 39 with loss 0.091169\n",
      "On batch 40 with loss 0.091267\n",
      "On batch 41 with loss 0.090345\n",
      "On batch 42 with loss 0.091675\n",
      "On batch 43 with loss 0.090870\n",
      "On batch 44 with loss 0.090804\n",
      "On batch 45 with loss 0.091593\n",
      "On batch 46 with loss 0.091108\n",
      "On batch 47 with loss 0.091091\n",
      "On batch 48 with loss 0.091499\n",
      "On batch 49 with loss 0.090439\n",
      "On batch 51 with loss 0.181652\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-848bd0c9db30>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomputing_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Train the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Generate the outputs for test data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0msave_to_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_fname\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Save the generated outputs to a file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-fcf8bcbe5b2a>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, X_train, X_valid, cfg)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m             \u001b[1;31m# Process the batch for data and labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 181\u001b[1;33m             \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprocess_train_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatchFrame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    182\u001b[0m             \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomputing_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomputing_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-fcf8bcbe5b2a>\u001b[0m in \u001b[0;36mprocess_train_data\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[1;31m# Beer style also gets one-hot\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[1;31m# Overall does not\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m     \u001b[0mreviews\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchar2oh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpadded\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtranslate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m     \u001b[1;32mdel\u001b[0m \u001b[0mpadded\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-fcf8bcbe5b2a>\u001b[0m in \u001b[0;36mchar2oh\u001b[1;34m(padded, translate, beers)\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[0migrid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmgrid\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mpadded\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpadded\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[1;31m# Index with ch, we use meshgrid since this is a 3d array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m     \u001b[0mchars\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0migrid\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0migrid\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;31m# Concatenate overall and beer style\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    train_data_fname = \"Beeradvocate_Train.csv\"\n",
    "    test_data_fname = \"Beeradvocate_Test.csv\"\n",
    "    out_fname = \"model_outputs.out\"\n",
    "    \n",
    "    train_data = load_data(train_data_fname) # Generating the pandas DataFrame\n",
    "    test_data = load_data(test_data_fname) # Generating the pandas DataFrame\n",
    "    X_train, X_valid = train_valid_split(train_data) # Splitting the train data into train-valid data\n",
    "    \n",
    "    model = baselineLSTM(cfg) # Replace this with model = <your model name>(cfg)\n",
    "    if cfg['cuda']:\n",
    "        computing_device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        computing_device = torch.device(\"cpu\")\n",
    "    model.to(computing_device)\n",
    "    \n",
    "    train(model, X_train, X_valid, cfg) # Train the model\n",
    "    outputs = generate(model, X_test, cfg) # Generate the outputs for test data\n",
    "    save_to_file(outputs, out_fname) # Save the generated outputs to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
