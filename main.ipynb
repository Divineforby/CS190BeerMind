{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from models import *\n",
    "from configs import cfg\n",
    "import pandas as pd\n",
    "from nltk.translate import bleu_score\n",
    "import pickle\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(fname):\n",
    "    # From the csv file given by filename and return a pandas DataFrame of the read csv.\n",
    "    \n",
    "    # Define path to data\n",
    "    # Note: Path relative to KHIEM's files, make changes to relative path if necessary\n",
    "    dataPath = 'BeerAdvocatePA4/' + fname\n",
    "    \n",
    "    # Read csv into pandas frame\n",
    "    df = pd.read_csv(dataPath)\n",
    "    \n",
    "    # Return frame\n",
    "    return df\n",
    "\n",
    "def char2oh(padded,translate, beers):\n",
    "    # Each row has form: beer style index||overall||character indices\n",
    "    # TODO: Onehot the beer style and concatenate to overall\n",
    "    # Onehot the character indices and concatenate the beerstyle||overall to each onehotted char\n",
    "    \n",
    "    # Each row's beer has form 1x#ofpossiblebeers\n",
    "    beerstyles = np.zeros((padded.shape[0],len(beers)))\n",
    "    # Each row's review has form max(lenofsequence) x #ofpossiblecharacters\n",
    "    # Since we padded each review, they all have the same number of characters\n",
    "    # Subtract two since we know the first two values aren't characters\n",
    "    chars = np.zeros((padded.shape[0], (padded.shape[1] - 2), len(translate)))\n",
    "    \n",
    "    # First two columns are beerstyle indices and overalls\n",
    "    bsidx = padded[:,0]\n",
    "    ovrl = padded[:,1]\n",
    "    \n",
    "    # The rest are characters\n",
    "    ch = padded[:,2:]\n",
    "    \n",
    "    # Index with bsidx\n",
    "    beerstyles[np.arange(padded.shape[0]), bsidx.astype(int)] = 1\n",
    "    \n",
    "    igrid = np.mgrid[0:padded.shape[0], 0:(padded.shape[1]-2)]\n",
    "    # Index with ch, we use meshgrid since this is a 3d array\n",
    "    chars[igrid[0], igrid[1], ch.astype(int)] = 1\n",
    "    \n",
    "    # Concatenate overall and beer style\n",
    "    meta_data = np.c_[ovrl, beerstyles]\n",
    "    \n",
    "    # Tile and reshape meta_data so we have a copy for each one of the characters\n",
    "    tiled_meta = np.tile(meta_data, padded.shape[1] - 2).reshape(padded.shape[0], (padded.shape[1] - 2), -1)\n",
    "    \n",
    "    # Concatenate the items \n",
    "    \n",
    "    # Return both the concatenated and just the one hot\n",
    "    return np.c_[tiled_meta, chars],ch\n",
    "    \n",
    "\n",
    "def process_train_data(data):\n",
    "    # TODO: Input is a pandas DataFrame and return a numpy array (or a torch Tensor/ Variable)\n",
    "    # that has all features (including characters in one hot encoded form).\n",
    "\n",
    "    # Get the dictionary to translate between ASCII and onehot index\n",
    "    with open(\"ASCII2oneHot.pkl\", \"rb\") as f:\n",
    "        translate = pickle.load(f)\n",
    "    \n",
    "    # Get the dictionary to translate between beer style and index\n",
    "    with open(\"BeerDict.pkl\", \"rb\") as f:\n",
    "        beers = pickle.load(f)\n",
    "        \n",
    "    # List of reviews to onehot after translation\n",
    "    toOnehot = []\n",
    "    \n",
    "    # For each review, convert to list of its translated characters\n",
    "    # Translated means ord(c) -> onehot index\n",
    "    # Also translate the beer style to its index value\n",
    "    # Concatenate all the data and convert to tensor\n",
    "    for idx,rev in data.iterrows():\n",
    "        if isinstance(rev['review/text'], str):\n",
    "            toOnehot.append(torch.Tensor([beers[rev['beer/style']]] + [rev['review/overall']] + \n",
    "                                         [translate[ord(x)] for x in list(chr(0)+rev['review/text']+chr(1))]))\n",
    "    \n",
    "    # No need to pad, we can just stack \n",
    "    padded = pad_data(toOnehot, translate[1])\n",
    "    del toOnehot\n",
    "\n",
    "    # Take the array padded sentences and one-hot the characters.\n",
    "    # Beer style also gets one-hot\n",
    "    # Overall does not\n",
    "    reviews,labels = char2oh(np.array(padded), translate, beers)\n",
    "    del padded\n",
    "    \n",
    "    # Since the labels are simply the next characters, we take all characters except the last one\n",
    "    # for the review, and everything but the first one for the labels\n",
    "    return torch.Tensor(reviews[:,0:-1,:]), torch.Tensor(labels[:,1:]).type(torch.LongTensor)\n",
    "    \n",
    "    \n",
    "def train_valid_split(data):\n",
    "    # TODO: Takes in train data as dataframe and\n",
    "    # splits it into training and validation data.\n",
    "    \n",
    "    # List of indices of the data\n",
    "    ind = np.arange(len(data))\n",
    "    \n",
    "    # Randomize the split\n",
    "    np.random.shuffle(ind)\n",
    "    \n",
    "    # Where to split the indices\n",
    "    # We'll take first 20% for validation, the rest for training\n",
    "    split = int(0.2*len(data))\n",
    "    \n",
    "    # Split the indices\n",
    "    vIndices = ind[0:split]\n",
    "    tIndices = ind[split:]\n",
    "    \n",
    "    # Group the indices into their frames then return those\n",
    "    validation_data = data.iloc[vIndices]\n",
    "    train_data = data.iloc[tIndices]\n",
    "    \n",
    "    return train_data,validation_data\n",
    "    \n",
    "def process_test_data(data):\n",
    "    # TODO: Takes in pandas DataFrame and returns a numpy array (or a torch Tensor/ Variable)\n",
    "    # that has all input features. Note that test data does not contain any review so you don't\n",
    "    # have to worry about one hot encoding the data.\n",
    "    \n",
    "    # Get the dictionary to translate between ASCII and onehot index\n",
    "    with open(\"ASCII2oneHot.pkl\", \"rb\") as f:\n",
    "        translate = pickle.load(f)\n",
    "    \n",
    "    # Get the dictionary to translate between beer style and index\n",
    "    with open(\"BeerDict.pkl\", \"rb\") as f:\n",
    "        beers = pickle.load(f)\n",
    "        \n",
    "    tostk = []\n",
    "    # Take each row and establish the metadata||<SOS> \n",
    "    for idx,rev in data.iterrows():\n",
    "        tostk.append(torch.Tensor([beers[rev['beer/style']]] + [rev['review/overall']] + \n",
    "                                     [translate[0]]))\n",
    "                        \n",
    "    # Stack the tensors\n",
    "    stked = torch.stack(tostk)\n",
    "    del tostk\n",
    "    \n",
    "    # Pass back the meta data to concatenate in each time step\n",
    "    orig = stked\n",
    "    stked, start = char2oh(np.array(stked), translate, beers)\n",
    "    \n",
    "    return torch.Tensor(stked), orig\n",
    "        \n",
    "\n",
    "    \n",
    "def pad_data(orig_data, pad):\n",
    "    # TODO: Since you will be training in batches and training sample of each batch may have reviews\n",
    "    # of varying lengths, you will need to pad your data so that all samples have reviews of length\n",
    "    # equal to the longest review in a batch. You will pad all the sequences with <EOS> character \n",
    "    # representation in one hot encoding.\n",
    "    # Data comes in as translated ASCII representation, simply sort and call torch pad\n",
    "    return torch.nn.utils.rnn.pad_sequence(sorted(orig_data, key = lambda x: len(x), reverse=True), \n",
    "                                           batch_first=True, padding_value=pad)\n",
    "    \n",
    "\n",
    "def getBatchIter(data, batchSize):\n",
    "    # TODO: Returns a list of batches of indices\n",
    "    # The list of batch indices will be used to index into the\n",
    "    # corresponding data frame to extract the data\n",
    "    \n",
    "    # List of all possible indices\n",
    "    ind = np.arange(len(data))\n",
    "    \n",
    "    # Calculate how many batches of batchSize would fit into\n",
    "    # into the length of the data\n",
    "    numBatches = int(len(data)/batchSize)\n",
    "    \n",
    "    # Split the array of indices into roughly equivalent batch sized batches\n",
    "    batchedInd = np.array_split(ind, numBatches)\n",
    "    \n",
    "    return batchedInd\n",
    "    \n",
    "def validate(model, validIter, X_valid):\n",
    "    # TODO: Run the model on the entire validation set for loss\n",
    "    # Loss\n",
    "    Criterion = torch.nn.CrossEntropyLoss()\n",
    "    # No need for gradient\n",
    "    with torch.no_grad():\n",
    "        totalLoss = 0\n",
    "        # Validation loop\n",
    "        for batch_count, batchInd in enumerate(validIter, 0):\n",
    "             # Get the dataframe for the batch\n",
    "            batchFrame = X_valid.iloc[batchInd]\n",
    "\n",
    "            # Process the batch for data and labels\n",
    "            batch, labels = process_train_data(batchFrame)\n",
    "            batch, labels = batch.to(computing_device), labels.to(computing_device)\n",
    "            \n",
    "            # Run our batch through the model\n",
    "            # batch has shape Batchsize x Seqlen x Input Dim\n",
    "            output, (h,c) = model(batch)\n",
    "            \n",
    "            # Save space\n",
    "            del h\n",
    "            del c\n",
    "            \n",
    "            # Reshape the output and labels to so that the loss function\n",
    "            # can simply interpret time as another batch\n",
    "            # This will be fine since sum of sum can be thought of as just\n",
    "            # one sum\n",
    "            output = output.contiguous().view(-1, output.shape[2])\n",
    "            labels = labels.view(-1)\n",
    "\n",
    "            # Get loss and compute gradients\n",
    "            loss = Criterion(output,labels)\n",
    "            totalLoss += float(loss)\n",
    "            \n",
    "            del output\n",
    "            del labels\n",
    "            del loss\n",
    "            \n",
    "            # Progress bar\n",
    "            if batch_count % 50 == 0:\n",
    "                print(\"Validation: On batch %d\" % (batch_count))\n",
    "                \n",
    "        # Return the average loss over the batch count\n",
    "        return totalLoss/(batch_count+1)\n",
    "            \n",
    "\n",
    "def train(model, X_train, X_valid, cfg):\n",
    "    # TODO: Train the model!\n",
    "    # Datas are given as pandas data frame. Call process on-line as we train to\n",
    "    # get the data and label\n",
    "    \n",
    "    epochs = np.arange(cfg['epochs'])\n",
    "    l_rate = cfg['learning_rate']\n",
    "    penalty = cfg['L2_penalty']\n",
    "    \n",
    "    \n",
    "    # Define loss and optimizer\n",
    "    Criterion = torch.nn.CrossEntropyLoss() # We'll use cross entropy\n",
    "    Optimizer = optim.Adam(model.parameters(), lr=l_rate, weight_decay=penalty) # Let's use ADAM\n",
    "    \n",
    "    # Size of each batch\n",
    "    trainbatchSize = 64\n",
    "    validbatchSize = 128\n",
    "    \n",
    "    # Create the batch iterator for the data\n",
    "    trainIter = getBatchIter(X_train, trainbatchSize)\n",
    "    validIter = getBatchIter(X_valid, validbatchSize)\n",
    "    \n",
    "    # For graphs\n",
    "    all_loss = []\n",
    "    v_loss = []\n",
    "    \n",
    "    # Early stopping conditions\n",
    "    thresh = 2\n",
    "    spikes = 0\n",
    "    \n",
    "    # Training loop\n",
    "    for e in epochs:\n",
    "        batch_loss = 0\n",
    "        for batch_count, batchInd in enumerate(trainIter,0):\n",
    "            # Get the dataframe for the batch\n",
    "            batchFrame = X_train.iloc[batchInd]\n",
    "\n",
    "            # Process the batch for data and labels\n",
    "            batch, labels = process_train_data(batchFrame)\n",
    "            batch, labels = batch.to(computing_device), labels.to(computing_device)\n",
    "\n",
    "            # Run our batch through the model\n",
    "            # batch has shape Batchsize x Seqlen x Input Dim\n",
    "            output, (h,c) = model(batch)\n",
    "            \n",
    "            # Save space\n",
    "            del h\n",
    "            del c\n",
    "            \n",
    "            # Reshape the output and labels to so that the loss function\n",
    "            # can simply interpret time as another batch\n",
    "            # This will be fine since sum of sum can be thought of as just\n",
    "            # one sum\n",
    "\n",
    "            output = output.contiguous().view(-1, output.shape[2])\n",
    "            labels = labels.view(-1)\n",
    "            \n",
    "            # Reset the gradients of the graph\n",
    "            Optimizer.zero_grad()\n",
    "            # Get loss and compute gradients\n",
    "            loss = Criterion(output,labels)\n",
    "            loss.backward()\n",
    "            \n",
    "          \n",
    "            # Clip the gradient so it doesn't explode\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "            \n",
    "            # Optimize step\n",
    "            Optimizer.step()\n",
    "            batch_loss += float(loss)\n",
    "            \n",
    "            # Delete unneeded references\n",
    "            del loss\n",
    "            del output\n",
    "            del batch\n",
    "            del labels\n",
    "            \n",
    "            # Progress bar\n",
    "            if batch_count % 50 == 0:\n",
    "                batch_loss /= 50\n",
    "                print(\"On batch %d with loss %f\" % (batch_count, batch_loss))\n",
    "                all_loss.append(batch_loss)\n",
    "                batch_loss = 0\n",
    "                \n",
    "                # Flush the write buffer\n",
    "                sys.stdout.flush()\n",
    "                \n",
    "            # Save model checkpoint\n",
    "            if batch_count % 1000 == 0:\n",
    "                # Model checkpoint\n",
    "                torch.save(model.state_dict(), 'ModelCheckpoints/LSTM.mdl')   \n",
    "                \n",
    "            # TODO: Implement validation\n",
    "            \n",
    "            if batch_count % 3500 == 0:\n",
    "                # Validate and save\n",
    "                vloss = validate(model, validIter, X_valid)\n",
    "                print(\"Validation on epoch %d on batch % has loss %f\" % (e,batch_count,vloss))\n",
    "                v_loss.append(vloss)\n",
    "                \n",
    "                # If there's more than one loss, we can start comparing\n",
    "                # to check for early stopping\n",
    "                if len(v_loss) > 1:\n",
    "                    \n",
    "                    # If we see an increase, we add 1 to the counter\n",
    "                    if v_loss[-1] > v_loss[-2]:\n",
    "                        spike += 1\n",
    "                    # Else, we reset the counter\n",
    "                    else:\n",
    "                        spike = 0\n",
    "                    \n",
    "                    # If we have continously spiked >=- thresh, we stop\n",
    "                    if spike >= thresh:\n",
    "                        print(\"Early stopping on epoch %d\" % e)\n",
    "                        return\n",
    "                \n",
    "            \n",
    "        print(\"Completed epoch %d\" % e)\n",
    "    \n",
    "    print(\"Completed Training after %d epochs\" % e)\n",
    "        \n",
    "    \n",
    "    \n",
    "def generate(model, X_test, cfg):\n",
    "    # TODO: Given n rows in test data, generate a list of n strings, where each string is the review\n",
    "    # corresponding to each input row in test data.\n",
    "    \n",
    "    # Get the dictionary to translate between ASCII and onehot index\n",
    "    with open(\"ASCII2oneHot.pkl\", \"rb\") as f:\n",
    "        translate = pickle.load(f)\n",
    "    \n",
    "    # Get the dictionary to translate between beer style and index\n",
    "    with open(\"BeerDict.pkl\", \"rb\") as f:\n",
    "        beers = pickle.load(f)\n",
    "    allGenerated = []\n",
    "    with torch.no_grad():\n",
    "        # Get iterator\n",
    "        testIter = getBatchIter(X_test, batchSize = 1)\n",
    "    \n",
    "        for batch_count, batchInd in enumerate(testIter, 0):\n",
    "            print(batch_count)\n",
    "             # Get the dataframe for the batch\n",
    "            batchFrame = X_test.iloc[batchInd]\n",
    "\n",
    "            # Process the batch for test data\n",
    "            # Orig is the array of meta data and <SOS> character\n",
    "            batch, orig = process_test_data(batchFrame)\n",
    "            batch = batch.to(computing_device)\n",
    "            \n",
    "            # Starting characters and meta datas for the next time step\n",
    "            start = orig[:,-1]\n",
    "            metas = orig[:,0:2]\n",
    "            \n",
    "            # The generated strings so far\n",
    "            generated = np.array(start).reshape(-1,1)\n",
    "            \n",
    "            probs, hc = model(batch)\n",
    "            # While not all batches have at least one EOS we continue generating.\n",
    "            while(not((generated == 110).any(axis=1).all())):\n",
    "                # Batch is in the shape of batchSize x 1 x input dim\n",
    "                # Feed the batch to get the outputs\n",
    "                probs, hc = model(batch, hc)\n",
    "\n",
    "                # Softmax over the input dim to get the probabilities\n",
    "                # Divide by temperature to implement the temperature softmax\n",
    "                probs = torch.nn.functional.softmax(probs/cfg['gen_temp'], dim = 2)\n",
    "\n",
    "                # Sample from our batchsize of probabilities to get batchsize of next output\n",
    "                sampled = np.array(torch.distributions.Categorical(probs).sample())\n",
    "\n",
    "                # Concatenate the sampled to our generated\n",
    "                generated = np.c_[generated,sampled]\n",
    "                \n",
    "                # Make our next input\n",
    "                newInput,_ = char2oh(np.c_[metas, sampled], translate, beers)\n",
    "                batch = torch.Tensor(newInput)\n",
    "                batch = batch.to(computing_device)\n",
    "            \n",
    "            allGenerated.append(generated)\n",
    "        \n",
    "            return allGenerated\n",
    "        \n",
    "    \n",
    "def save_to_file(outputs, fname):\n",
    "    # TODO: Given the list of generated review outputs and output file name, save all these reviews to\n",
    "    # the file in .txt format.\n",
    "    raise NotImplementedError\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On batch 0 with loss 0.093837\n",
      "Validation: On batch 0\n",
      "Validation: On batch 50\n",
      "Validation: On batch 100\n",
      "Validation: On batch 150\n",
      "Validation: On batch 200\n",
      "Validation: On batch 250\n",
      "Validation: On batch 300\n",
      "Validation: On batch 350\n",
      "Validation: On batch 400\n",
      "Validation: On batch 450\n",
      "Validation: On batch 500\n",
      "Validation: On batch 550\n",
      "Validation: On batch 600\n",
      "Validation: On batch 650\n",
      "Validation: On batch 700\n",
      "Validation: On batch 750\n",
      "Validation: On batch 800\n",
      "Validation: On batch 850\n",
      "Validation: On batch 900\n",
      "Validation: On batch 950\n",
      "Validation: On batch 1000\n",
      "Validation: On batch 1050\n",
      "Validation: On batch 1100\n",
      "Validation: On batch 1150\n",
      "Validation: On batch 1200\n",
      "Validation: On batch 1250\n",
      "Validation: On batch 1300\n",
      "Validation: On batch 1350\n",
      "Validation: On batch 1400\n",
      "Validation: On batch 1450\n",
      "Validation: On batch 1500\n",
      "Validation: On batch 1550\n",
      "Validation: On batch 1600\n",
      "Validation: On batch 1650\n",
      "Validation: On batch 1700\n",
      "Validation: On batch 1750\n",
      "Validation: On batch 1800\n",
      "Validation: On batch 1850\n",
      "Validation: On batch 1900\n",
      "Validation: On batch 1950\n",
      "Validation on epoch 0 on batch 0s loss 4.641453\n",
      "On batch 50 with loss 3.780555\n",
      "On batch 100 with loss 3.360166\n",
      "On batch 150 with loss 3.261948\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    train_data_fname = \"Beeradvocate_Train.csv\"\n",
    "    test_data_fname = \"Beeradvocate_Test.csv\"\n",
    "    out_fname = \"model_outputs.out\"\n",
    "    \n",
    "    train_data = load_data(train_data_fname) # Generating the pandas DataFrame\n",
    "    test_data = load_data(test_data_fname) # Generating the pandas DataFrame\n",
    "    X_train, X_valid = train_valid_split(train_data) # Splitting the train data into train-valid data\n",
    "    \n",
    "    model = LSTM(cfg) # Replace this with model = <your model name>(cfg)\n",
    "    if cfg['cuda']:\n",
    "        computing_device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        computing_device = torch.device(\"cpu\")\n",
    "    model.to(computing_device)\n",
    "    \n",
    "    train(model, X_train, X_valid, cfg) # Train the model\n",
    "    #outputs = generate(model, X_test, cfg) # Generate the outputs for test data\n",
    "    #save_to_file(outputs, out_fname) # Save the generated outputs to a file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
