{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from models import *\n",
    "from configs import cfg\n",
    "import pandas as pd\n",
    "from nltk.translate import bleu_score\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(fname):\n",
    "    # From the csv file given by filename and return a pandas DataFrame of the read csv.\n",
    "    \n",
    "    # Define path to data\n",
    "    # Note: Path relative to KHIEM's files, make changes to relative path if necessary\n",
    "    dataPath = 'BeerAdvocatePA4/' + fname\n",
    "    \n",
    "    # Read csv into pandas frame\n",
    "    df = pd.read_csv(dataPath)\n",
    "    \n",
    "    # Return frame\n",
    "    return df\n",
    "\n",
    "\n",
    "def process_train_data(data):\n",
    "    # TODO: Input is a pandas DataFrame and return a numpy array (or a torch Tensor/ Variable)\n",
    "    # that has all features (including characters in one hot encoded form).\n",
    "    raise NotImplementedError\n",
    "\n",
    "    \n",
    "def train_valid_split(data, labels):\n",
    "    # TODO: Takes in train data and labels as numpy array (or a torch Tensor/ Variable) and\n",
    "    # splits it into training and validation data.\n",
    "    raise NotImplementedError\n",
    "    \n",
    "    \n",
    "def process_test_data(data):\n",
    "    # TODO: Takes in pandas DataFrame and returns a numpy array (or a torch Tensor/ Variable)\n",
    "    # that has all input features. Note that test data does not contain any review so you don't\n",
    "    # have to worry about one hot encoding the data.\n",
    "    raise NotImplementedError\n",
    "\n",
    "    \n",
    "def pad_data(orig_data):\n",
    "    # TODO: Since you will be training in batches and training sample of each batch may have reviews\n",
    "    # of varying lengths, you will need to pad your data so that all samples have reviews of length\n",
    "    # equal to the longest review in a batch. You will pad all the sequences with <EOS> character \n",
    "    # representation in one hot encoding.\n",
    "    raise NotImplementedError\n",
    "    \n",
    "\n",
    "def train(model, X_train, y_train, X_valid, y_valid, cfg):\n",
    "    # TODO: Train the model!\n",
    "    raise NotImplementedError\n",
    "    \n",
    "    \n",
    "def generate(model, X_test, cfg):\n",
    "    # TODO: Given n rows in test data, generate a list of n strings, where each string is the review\n",
    "    # corresponding to each input row in test data.\n",
    "    raise NotImplementedError\n",
    "    \n",
    "    \n",
    "def save_to_file(outputs, fname):\n",
    "    # TODO: Given the list of generated review outputs and output file name, save all these reviews to\n",
    "    # the file in .txt format.\n",
    "    raise NotImplementedError\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-763299f7153a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mtrain_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data_fname\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Generating the pandas DataFrame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mtest_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data_fname\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Generating the pandas DataFrame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprocess_train_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Converting DataFrame to numpy array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_valid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_valid_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Splitting the train data into train-valid data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprocess_test_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Converting DataFrame to numpy array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-27-7ce4bfe0795f>\u001b[0m in \u001b[0;36mprocess_train_data\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;31m# TODO: Input is a pandas DataFrame and return a numpy array (or a torch Tensor/ Variable)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;31m# that has all features (including characters in one hot encoded form).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    train_data_fname = \"Beeradvocate_train.csv\"\n",
    "    test_data_fname = \"Beeradvocate_test.csv\"\n",
    "    out_fname = \"model_outputs.out\"\n",
    "    \n",
    "    train_data = load_data(train_data_fname) # Generating the pandas DataFrame\n",
    "    test_data = load_data(test_data_fname) # Generating the pandas DataFrame\n",
    "    train_data, train_labels = process_train_data(train_data) # Converting DataFrame to numpy array\n",
    "    X_train, y_train, X_valid, y_valid = train_valid_split(train_data, train_labels) # Splitting the train data into train-valid data\n",
    "    X_test = process_test_data(test_data) # Converting DataFrame to numpy array\n",
    "    \n",
    "    model = baselineLSTM(cfg) # Replace this with model = <your model name>(cfg)\n",
    "    if cfg['cuda']:\n",
    "        computing_device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        computing_device = torch.device(\"cpu\")\n",
    "    model.to(computing_device)\n",
    "    \n",
    "    train(model, X_train, y_train, X_valid, y_valid, cfg) # Train the model\n",
    "    outputs = generate(model, X_test, cfg) # Generate the outputs for test data\n",
    "    save_to_file(outputs, out_fname) # Save the generated outputs to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          A lot of foam. But a lot.\\tIn the smell some b...\n",
       "1          Dark red color, light beige foam, average.\\tIn...\n",
       "2          Almost totally black. Beige foam, quite compac...\n",
       "3          Golden yellow color. White, compact foam, quit...\n",
       "4          According to the website, the style for the Ca...\n",
       "5          Poured from the bottle into a Chimay goblet.\\t...\n",
       "6          22 oz bottle from \"Lifesource\" Salem. $3.95 Ni...\n",
       "7          Bottle says \"Malt beverage brewed with Ginger ...\n",
       "8          I'm not sure why I picked this up... I like gi...\n",
       "9          Poured from a 22oz bomber into my Drie Fontein...\n",
       "10         OK, so the only reason I bought this while sho...\n",
       "11         Notes from 6/24\\t\\tA: Bright golden glowing be...\n",
       "12         22 oz. bomber,\\t\\tA: Pours a clear yellow with...\n",
       "13         Is it possible for a bottle to be a novelty pr...\n",
       "14         Brown in color, somewhere between a porter and...\n",
       "15         Caldera presents yet another circumstance wher...\n",
       "16         More of a 'dry' than a lager, tasted at the 20...\n",
       "17         Pours a murky light brown with a 1 inch fizzy ...\n",
       "18         Faint sudsy head with some with some dissipati...\n",
       "19         A new arrival to the West TN area... \\t\\tPours...\n",
       "20         Sampled 10/30/11 - Transferring the notes.\\t\\t...\n",
       "21         This is my first rauchbier. \\tPours a burnt am...\n",
       "22         A: Pours a rich, ruby color, clear. Maybe a fi...\n",
       "23         Pours a mahogany color, rich, with a tan head....\n",
       "24         Pours light caramel brown with reddish highlig...\n",
       "25         Poured a slightly cloudy deep amber/red color ...\n",
       "26         Big thanks to N2168 for knocking this off my w...\n",
       "27         On tap last night at the Caldera Tap House.\\t\\...\n",
       "28         22 oz. Think I picked this up in Chicago Binny...\n",
       "29         Poured into a 1/2 liter stein a deep rich ambe...\n",
       "                                 ...                        \n",
       "1269261    Served in a standard pint glass. Poured a hazy...\n",
       "1269262    Clear amber with a beautifully dense white hea...\n",
       "1269263    I'm always a bit apprehensive when it comes to...\n",
       "1269264    Got this at the LCBO\\t\\tFrom a bottle into a p...\n",
       "1269265    Appearance: cloudy amber, with a creamy head t...\n",
       "1269266    Nice malt aroma of familiar British style. Sli...\n",
       "1269267    A: Pours a transparent gold color that creates...\n",
       "1269268    16oz nitro can poured into a shaker pint glass...\n",
       "1269269    Another entry from NSLC's 'Beers of the World'...\n",
       "1269270    Pours a oft-amber color. Scents of roasted nut...\n",
       "1269271    A: Pours a dark golden red with a thick, cream...\n",
       "1269272    12 oz into a pint\\t\\tA - Pours an extremely cl...\n",
       "1269273    Has a nice amber color with a beautiful smooth...\n",
       "1269274    On tap at Boulevard Tavern, Brooklyn, NY.\\t\\tA...\n",
       "1269275    From the nitro can, this is basically the same...\n",
       "1269276    It is red amber with a fairly creamy off-white...\n",
       "1269277    Serving type - nitro can poured into a mug.\\t\\...\n",
       "1269278    Sampled from a 12oz bottle in a standard pint ...\n",
       "1269279    A: Nice copper color with one finger tan head ...\n",
       "1269280    Serveing: On Tap at The Curragh Irish Pub\\tApp...\n",
       "1269281    I thought this classic English Ale would be on...\n",
       "1269282    This one is a little malty on the nose, with a...\n",
       "1269283    Reddish orange in color, it comes in a clear b...\n",
       "1269284    I decided to try one of these since I own an M...\n",
       "1269285    A clear copper color body with a small white h...\n",
       "1269286    Drank this out of a bottle. My first pale ale ...\n",
       "1269287    A-Pours cloudy at first like all nitro cans, b...\n",
       "1269288    Poured into a pint glass.\\t\\tA: Pours a clear ...\n",
       "1269289    Pours a clear whiskey-amber color with some wh...\n",
       "1269290    Poured this 14.9 oz. nitro can into a British ...\n",
       "Name: review/text, Length: 1269291, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ptorch]",
   "language": "python",
   "name": "conda-env-ptorch-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
